{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00. 文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "txt=\"stressed\"\n",
    "print(txt[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. パトカー」＋「タクシー」＝「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "txt01=\"パトカー\"\n",
    "txt02=\"タクシー\"\n",
    "\n",
    "combine_txts=\"\"\n",
    "for i in range(len(txt01)):\n",
    "    combine_txts+=txt01[i]+txt02[i]\n",
    "print(combine_txts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "txt=\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "words=txt.split()\n",
    "num_of_characters_of_words=[]\n",
    "for i in range(len(words)):\n",
    "    clean_words = words[i].strip(',.') #stripメソッド=特定の文字列の削除\n",
    "    num_of_characters_of_words.append(len(clean_words))\n",
    "print(num_of_characters_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. 元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "txt=\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "words=txt.split()\n",
    "dict_word_and_pos=dict()\n",
    "head_one=[1,5,6,7,8,9,15,16,19]\n",
    "for i in range(len(words)):\n",
    "    if i+1 in head_one:\n",
    "        tmp=words[i][:1] #単語から1文字取り出し\n",
    "        dict_word_and_pos[tmp]=i+1 #取り出した単語の位置\n",
    "    else:\n",
    "        tmp=words[i][:2]\n",
    "        dict_word_and_pos[tmp]=i+1\n",
    "\n",
    "print(dict_word_and_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．\n",
    "\n",
    "この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語gram [['I', 'am'], ['am', 'an'], ['an', 'NLPer'], ['NLPer']]\n",
      "文字gram ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er', 'r']\n"
     ]
    }
   ],
   "source": [
    "def n_gram(num,txt):\n",
    "    words=txt.split()\n",
    "    char=txt.replace(\" \",\"\") #replaceメソッドで文字列に含まれている空白文字を削除\n",
    "    word_gram=[]\n",
    "    char_gram=[]\n",
    "    for i in range(len(words)):#単語gram\n",
    "        word_gram.append(words[i:i+num])\n",
    "    for j in range(len(char)): #文字gram\n",
    "        char_gram.append(char[j:j+num])\n",
    "    return word_gram, char_gram\n",
    "\n",
    "\n",
    "num_of_gram=2\n",
    "txt_input=\"I am an NLPer\"\n",
    "w,c=n_gram(num_of_gram,txt_input)\n",
    "print(\"単語gram\",w)\n",
    "print(\"文字gram\",c)\n",
    "\n",
    "#後述\n",
    "#ポイント：半角スペース削除にはreplace関数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. 集合\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．\n",
    "\n",
    "さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 {'is', 'ra', 'pa', 'ad', 'ag', 'ph', 'gr', 'ap', 'ar', 'se', 'e', 'h', 'di'}\n",
      "積集合 {'pa', 'ap', 'ar', 'ra'}\n",
      "差集合 {'is', 'ad', 'e', 'se', 'di'}\n",
      "se はXに含まれる\n"
     ]
    }
   ],
   "source": [
    "def n_gram(num,txt):\n",
    "    words=txt.split()\n",
    "    char=txt.replace(\" \",\"\") #replaceメソッドで文字列に含まれている空白文字を削除\n",
    "    word_gram=[]\n",
    "    char_gram=[]\n",
    "    for i in range(len(words)):#単語gram\n",
    "        word_gram.append(words[i:i+num])\n",
    "    for j in range(len(char)): #文字gram\n",
    "        char_gram.append(char[j:j+num])\n",
    "    return word_gram, char_gram\n",
    "\n",
    "num_of_gram=2\n",
    "txt01=\"paraparaparadise\"\n",
    "txt02=\"paragraph\"\n",
    "\n",
    "_, char_gram_txt01=n_gram(num_of_gram,txt01)\n",
    "_, char_gram_txt02=n_gram(num_of_gram,txt02)\n",
    "\n",
    "X=set(char_gram_txt01)\n",
    "Y=set(char_gram_txt02)\n",
    "print(\"和集合\",X|Y)\n",
    "print(\"積集合\",X&Y)\n",
    "print(\"差集合\",X-Y) \n",
    "\n",
    "The_word=\"se\"\n",
    "if The_word in X and The_word in Y:\n",
    "    print(The_word,\"はX及びYに含まれる\")\n",
    "elif The_word in X:\n",
    "    print(The_word,\"はXに含まれる\")\n",
    "elif The_word in Y:\n",
    "    print(The_word,\"はYに含まれる\")\n",
    "else:\n",
    "    print(The_word,\"はXとYに含まれない\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．\n",
    "さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def make_string(time,name,value):\n",
    "    string=time+\"時の\"+name+\"は\"+value\n",
    "    return string\n",
    "\n",
    "x,y,z=map(str,(input()).split())\n",
    "print(make_string(x,y,z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08. 暗号文(もう一度解きたい)\n",
    "\n",
    "与えられた文字列の各文字を、以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "英小文字ならば(219 - 文字コード)の文字に置換\n",
    "その他の文字はそのまま出力\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字列 I am a graduate student.\n",
      "暗号化 I zn z tizwfzgv hgfwvmg.\n",
      "暗号化 I am a graduate student.\n"
     ]
    }
   ],
   "source": [
    "def cipher(txt):\n",
    "    txt_list=[]\n",
    "    result=\"\"\n",
    "\n",
    "    for i in range(len(txt)):\n",
    "        #i番目が小文字の場合\n",
    "        if txt[i].islower():\n",
    "            txt_list.append(chr(219-ord(txt[i])))\n",
    "        #i番目が小文字以外の場合\n",
    "        else:\n",
    "            txt_list.append(txt[i])\n",
    "        #リストを英文字列に\n",
    "        result+=txt_list[i]\n",
    "\n",
    "    return result\n",
    "\n",
    "txt_input=\"I am a graduate student.\"\n",
    "print(\"文字列\",txt_input)\n",
    "txt_input=\"I am a graduate student.\"\n",
    "encode=cipher(txt_input)\n",
    "print(\"暗号化\",encode)\n",
    "decode=cipher(encode)\n",
    "print(\"暗号化\",decode)\n",
    "\n",
    "#ポイント\n",
    "#ord=その文字のUnicodeコードポイントを表す整数を返す関数でchr関数は、数値で指定した文字コードを返す関数\n",
    "#chr(97)→a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09. Typoglycemia(もう一度解きたい)\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I conu'ldt blieeve that I could aalltcuy ursnnedtad what I was reandig : the poeannhmel power of the human mind.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "txt=\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind.\"\n",
    "txt=txt.replace(\".\",\"\")\n",
    "words=txt.split()\n",
    "result=\"\"\n",
    "for the_word in words:  \n",
    "    if len(the_word)>5:\n",
    "        random_word=the_word[0]+''.join(random.sample(the_word[1:-1],len(the_word[1:-1])))+the_word[-1]\n",
    "        result+=random_word+\" \"\n",
    "    else:\n",
    "        result+=the_word+\" \"\n",
    "result=result[:-1]+\".\" #resultは一つの文字列になっている。最後の半角スペースをピリオドに変更\n",
    "print(result)\n",
    "#ポイント\n",
    "#文字列やタプルをシャッフルしたい場合は新たなオブジェクトを生成するrandom.sample()を使う。\n",
    "#引数に文字列やタプルを指定した場合もrandom.sample()はリストを返す.\n",
    "#文字列の場合は一文字ずつのリストとなる。再度ひとつの文字列に連結するにはjoin()メソッドを使う。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m1_ai_lec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
