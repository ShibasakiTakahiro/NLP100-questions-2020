{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第５章 機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50. データの入手・整形\n",
    "News Aggregator Data Setをダウンロードし、以下の要領で学習データ（train.txt），検証データ（valid.txt），評価データ（test.txt）を作成せよ．\n",
    "\n",
    "1. ダウンロードしたzipファイルを解凍し，readme.txtの説明を読む．\n",
    "2. 情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する．\n",
    "3. 抽出された事例をランダムに並び替える．\n",
    "4. 抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する．ファイルには，１行に１事例を書き出すこととし，カテゴリ名と記事見出しのタブ区切り形式とせよ（このファイルは後に問題70で再利用する）．\n",
    "\n",
    "　学習データと評価データを作成したら，各カテゴリの事例数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 区切りがタブ\\tのためread_tableを使う\n",
    "base_path=\"./files/chap6\"\n",
    "#indx_col=0: csvファイルの最初の列をインデックスとして扱う。つまりデータとして扱う。namesで列名をつける。\n",
    "#指定された情報源を抜き出す。\n",
    "df=pd.read_table(f\"{base_path}/news+aggregator/newsCorpora.csv\", index_col=0, names=(\"ID\", \"TITLE\", \"URL\", \"PUBLISHER\", \"CATEGORY\", \"STORY\", \"HOSTNAME\", \"TIMESTAMP\"))\n",
    "df_1 = df[(df[\"PUBLISHER\"]==\"Reuters\")|(df[\"PUBLISHER\"]==\"Huffington Post\")|\n",
    "          (df[\"PUBLISHER\"]==\"Businessweek\")|(df[\"PUBLISHER\"]==\"Contactmusic.com\")|\n",
    "          (df[\"PUBLISHER\"]==\"Daily Mail\")].loc[:, [\"CATEGORY\", \"TITLE\"]]#カテゴリーとタイトルを抽出\n",
    "#df_1[\"TITLE\"].str.contains(\"http\")：TITLE列にhttpが含まれるかをチェックする\n",
    "#~演算子：ブール値を反転する。これによりhttpを含まない行を選択する。\n",
    "# すなわちタイトルにURLが含まれる記事を除外する\n",
    "df_1= df_1[~df_1[\"TITLE\"].str.contains(\"http\")]\n",
    "df_train,df_test=train_test_split(df_1, test_size=0.2) #trainとtestで8:2に分割\n",
    "df_test, df_valid=train_test_split(df_test, test_size=0.5) #さらにtestを、testとvalidで1:1で分割\n",
    "\n",
    "#タブ区切りで保存、index=Falseでインデックスをファイルに出力しない。index=FalseでID, CATEGORY, TITLEで出力される\n",
    "df_train.to_csv(f\"{base_path}/train.txt\",sep=\"\\t\", index=False)\n",
    "df_test.to_csv(f\"{base_path}/test.txt\", sep=\"\\t\",index=False) \n",
    "df_valid.to_csv(f\"{base_path}/valid.txt\", sep=\"\\t\", index=False) #CATEGORY, TITLEで出力される\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10672\n",
      "1335\n",
      "1335\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{base_path}/train.txt\",\"r\") as f:\n",
    "    all_list=f.readlines()\n",
    "    print(len(all_list))\n",
    "with open(f\"{base_path}/test.txt\",\"r\") as f:\n",
    "    all_list=f.readlines()\n",
    "    print(len(all_list))\n",
    "with open(f\"{base_path}/valid.txt\",\"r\") as f:\n",
    "    all_list=f.readlines()\n",
    "    print(len(all_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m1_ai_lec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
